---
title: "Assignment1+2tryagaion"
author: "Nanna Bernth"
date: "23 sep 2018"
output: html_document
---

# Template for the hand-in
### Structure of the code chunks

Basic stuff:
- Loading the libraries
- Setting the directory and loading the data
- Look at the data (which variables are there? Are they in the right format?) and describe the participants (by diagnosis)

We will try to answer three questions:
    
- Do children with ASD develop language differently from non-ASD children?
- Do parents speak differently to children with ASD than to non-ASD ones?
- Which variables should we use to best explain the child linguistic performance?

### Loading the relevant libraries

Load necessary libraries : what will you need?

- e.g. something to plot with
- e.g. mixed effects models

```{r Load Libraries, include = FALSE}

library(pacman)
p_load(lmerTest, pastecs, ggplot2, tidyverse, gdata, MuMIn, effects)

```

### Define your working directory and load the data
If you created a project for this class and opened this Rmd file from within that project, your working directory is your project directory.

If you opened this Rmd file outside of a project, you will need some code to find the data:
- Create a new variable called locpath (localpath)
- Set it to be equal to your working directory
- Move to that directory (setwd(locpath))
- Load the data you saved last time (use read_csv(fileName))

If your're in a project, just put the data in the project folder and you're good to go! (Or make a data subfolder to keep it tidy around here)

```{r Load Data, include = FALSE}

locpath= "C:/Users/nanna/OneDrive - Aarhus universitet/3. Semester/Experimental Methods 3/LanguageDevelopmentASD"

setwd(locpath)
data = read.csv("LanguageASD.csv")
getwd()

```

#Renaming vars
```{r}
data <- rename.vars(data, "Diagnosis", "diagnosis")
data <- rename.vars(data, "Gender", "gender")
data <- rename.vars(data, "Age", "age")
data <- rename.vars(data, "Ethnicity", "ethnicity")
data <- rename.vars(data, "Visit", "visit")
data <- rename.vars(data, "ADOS1", "ados1")
data <- rename.vars(data, "MullenRaw1", "nonverbalIQ")
data <- rename.vars(data, "ExpressiveLangRaw1", "verbalIQ")

```

### Characterize the participants (Exercise 1)

Identify relevant variables: participants demographic characteristics, diagnosis, ADOS, Verbal IQ, Non Verbal IQ, Visit, Number of words used, Number of unique words used, length of utterance in both child and parents.

Make sure the variables are in the right format.

Describe the characteristics of the two groups of participants and whether the two groups are well matched.

```{r}
# Counting diagnosis
data %>%
  filter(visit==1)%>%
  count(diagnosis)

# Counting gender
data %>%
  filter(visit==1)%>%
  count(gender)

# Ethnicity
data %>%
  filter(visit==1)%>%
  count(ethnicity)

# Age spectrum from 1st visit
mean(data$age[data$visit=="1"], na.rm = T)

# Finding means
mean(data$age[data$diagnosis=="ASD"], na.rm = T)
mean(data$age[data$diagnosis=="TD"], na.rm = T)

# MLU mean
mean(data$CHI_MLU[data$diagnosis=="ASD"], na.rm = T)
mean(data$CHI_MLU[data$diagnosis=="TD"], na.rm = T)

# Parents MLU mean
mean(data$MOT_MLU[data$diagnosis=="ASD"], na.rm = T)
mean(data$MOT_MLU[data$diagnosis=="TD"], na.rm = T)

# nonverbalIQ mean
mean(data$nonverbalIQ[data$diagnosis=="ASD"], na.rm = T)
mean(data$nonverbalIQ[data$diagnosis=="TD"], na.rm = T)
 
# verbalIQ mean 
mean(data$verbalIQ[data$diagnosis=="ASD"], na.rm = T) 
mean(data$verbalIQ[data$diagnosis=="TD"], na.rm = T) 
 

#Summary by diagnosis
data_ads <- data %>% filter(diagnosis == "ASD")
summary(data_ads)

data_td <- data %>% filter(diagnosis == "TD")
summary(data_td)


``` 


#Removing participants

```{r}
#Removing ID 11 and 66, 48, 50 due to false/lack of information

data <- data[-c (1, 68, 69, 130, 131, 132, 276, 277, 284, 285), ]

```


#Plotting the participant data

```{r descriptive stats, include = FALSE}

#Looking at the development over time in mean length of utterance for kids with and witout autism 


#Boxplot showing the two different groups of children (ASD and TD)
boxplot(CHI_MLU ~ visit+diagnosis, data = data,
        col = c("blue", "bisque"))


#Makeing a plot that shows the development of the ASD children versus the TD

xlab <- "Visit"
ylab <- "Mean Lenght of Utterance"


#PLOT WITH MEAN LINEAR LINE
ggplot(data) + 
  aes(x = visit, y = CHI_MLU, color = ID) + 
  stat_smooth(method = "lm", col = "313131") +
  # Put the points on top of lines
  geom_point() +
  facet_wrap("diagnosis") +
  
  labs(x = xlab, y = ylab)

#PLOT WITH INDIVIDUAL LINEAR LINES

ggplot(data, aes(x = visit, y = CHI_MLU, group = ID)) +
  geom_smooth(method = "lm", se = F, aes(col = ID)) + 
  geom_point(aes(col = ID)) +
  facet_wrap(~ diagnosis) + 
  labs(x = xlab, y = ylab)


#Looking at the children individually - would a linear model be a good model?
#No, especially not for ADS kids


```


[REPORT THE RESULTS]


## Let's test hypothesis 1: Children with ASD display a language impairment  (Exercise 2)

### Hypothesis: The child's MLU changes: i) over time, ii) according to diagnosis

Let's start with a simple mixed effects linear model

Remember to plot the data first and then to run a statistical test.


- Which variable(s) should be included as fixed factors?

We include CHI_MLU and visit and diagnosis as the fixed effect (the effects of interest)

- Which variable(s) should be included as random factors?

Here we set the individual child (ID) as a random intercept (different MLU from the beginning) 

ID as a random slope (different development that cannot be genealized)


#Linear model
```{r ex2, include = FALSE}

model1 <- lmer(CHI_MLU ~ visit + diagnosis + (1 + visit | ID), data = data, REML = F)

summary(model1)

confint(model1)

```

How would you evaluate whether the model is a good model?

#Evaluating the linear model
```{r ex2 evaluate, include = FALSE}

#Checking for assumptions
qqnorm(residuals(model1))
hist(data$CHI_MLU)

round(stat.desc(residuals(model1)),2)
round(stat.desc(data[, c("age", "CHI_MLU")], norm = T), 4)


#Plotting the residuals
plot(fitted(model1),residuals(model1))^2

#R-squared
r.squaredGLMM(model1)


#Creating null-models
model1.null <- lmer(CHI_MLU ~ 1 + (1 + visit | ID), data = data, REML = F)

model1.null1 <- lmer(CHI_MLU ~ diagnosis + (1 + visit | ID), data = data, REML = F)

model1.null2 <- lmer(CHI_MLU ~ visit + (1 + visit | ID), data = data, REML = F)


#Comparing
anova(model1.null, model1)

```

Not too good, right? Let's check whether a growth curve model is better.
Remember: a growth curve model assesses whether changes in time can be described by linear, or quadratic, or cubic (or... etc.) components.

First build the different models, then compare them to see which one is better

```{r ex2 growth curve, include = FALSE}

#Creating the quadratic model
model_quadratic <- lmer(CHI_MLU ~ visit + I(visit^2) + diagnosis + (1+visit + I(visit^2)|ID), data = data, REML=FALSE)

summary(model_quadratic)

#Residual plot of  the model
plot(fitted(model_quadratic),residuals(model_quadratic))^2

r.squaredGLMM(model_quadratic)
##           R2m       R2c
## [1,] 0.2078746 0.8576933



#Creating the cubic model
model_cubic <- lmer(CHI_MLU ~ visit + I(visit^2) + I(visit^3) + diagnosis + (1+visit + I(visit^2) + I(visit^3)|ID), data = data, REML=FALSE)

summary(model_cubic)

#Residual plot of  the model
plot(fitted(model_cubic),residuals(model_cubic))^2


r.squaredGLMM(model_cubic)
##           R2m       R2c
##  [1,] 0.2195552 0.8784997


#Finding the best model
anova(model1.null, model1, model_quadratic, model_cubic)

```


Plotting the data as quadratic and cubic

```{r}
#Plotting quadratic - w. mean line
ggplot(data) + 
  aes(x = visit, y = CHI_MLU) + 
  stat_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  # Put the points on top of lines
  geom_point() +
  facet_wrap("diagnosis") +
  labs(x = xlab, y = ylab)


#Individual lines
ggplot(data = data, aes(x = visit, y = CHI_MLU, group = ID)) +
  geom_smooth(method = "lm", 
              formula = y ~ poly(x, 2), se = F, aes(color = ID)) + 
  geom_point(aes(col = ID)) + 
  facet_wrap(~ diagnosis) + 
  labs(x = xlab, y = ylab)



#Plotting cubic with mean line
ggplot(data) + 
  aes(x = visit, y = CHI_MLU) + 
   geom_point(aes(col = ID)) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), col= "orange") + 
  # Put the points on top of lines
   facet_wrap("diagnosis") +
  labs(x = xlab, y = ylab)


#Plotting with individual lines
ggplot(data, aes(x = visit, y = CHI_MLU, group = ID)) + 
  geom_smooth(method = "lm",
              formula = y ~ poly(x, 3), se = F, aes(color = ID)) + 
  geom_point(aes(col = ID)) + 
  facet_wrap(~ diagnosis) + 
  labs(x = xlab, y = ylab)

```


Plotting the predictions

```{r}
# Plotting our chosen model's predictions (the cubic model)

ee <- effect(c("diagnosis","visit"), model_cubic) 
theme_set(theme_bw())

ggplot(as.data.frame(ee),
    aes(visit,fit,colour=diagnosis, fill=diagnosis)) +
    geom_line() +
    ## colour=NA suppresses edges of the ribbon
    geom_ribbon(colour=NA,alpha=0.1, aes(ymin=lower,ymax=upper)) +
    labs(title = "Predicting child MLU development from diagnosis", x = "Visit", y = "MLU")
```



Exciting right?
Now it's time to report our results.


Remember to report:
- the estimates for each predictor (beta estimate, standard error, p-value)
- A plain word description of the results
- A plot of your best model's predictions


[REPORT THE RESULTS]
Linguistic development of children MLU is affected by ... 



## Let's test hypothesis 2: Parents speak equally to children with ASD and TD  (Exercise 3)
```{r}

#Plotting the MLU of parent 
boxplot(MOT_MLU ~ visit+diagnosis, data = data,
        col = c("blue", "bisque"))
```



### Hypothesis: Parental MLU changes: i) over time, ii) according to diagnosis

```{r ex3, include = FALSE}

Parental_MLU <- lmer(MOT_MLU ~ visit + diagnosis + (1 + visit | ID), data = data, REML = F)
summary(Parental_MLU)


#Linear plot

ggplot(data = data, aes(x = visit, y = MOT_MLU, group = ID)) +
  geom_smooth(method = "lm", se = F, aes(color = ID)) +
  geom_point(aes(col = ID)) + 
  facet_wrap(~ diagnosis) + 
  labs(x = xlab, y = ylab)

```


```{r ex3, include = FALSE}
#Quadratic Parental Model

Parental_model_quadratic <- lmer(MOT_MLU ~ visit + I(visit^2) + diagnosis + (1+visit + I(visit^2) |ID), data = data, REML=FALSE)

summary(Parental_model_quadratic)

#Residual plot
plot(fitted(Parental_model_quadratic),residuals(Parental_model_quadratic))^2


#Plotting
ggplot(data = data, aes(x = visit, y = MOT_MLU, group = ID)) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = F, aes(color = ID)) + 
  geom_point(aes(col = ID)) + 
  facet_wrap(~ diagnosis) + 
  labs(x = xlab, y = ylab)

#Mean line
ggplot(data = data, aes(x = visit, y = MOT_MLU)) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = F, color = "orange") + 
  geom_point(aes(col = ID)) + 
  facet_wrap(~ diagnosis) + 
  labs(x = xlab, y = ylab)

```


```{r ex3, include = FALSE}
#Cubic parental model

Parental_model_cubic <- lmer(MOT_MLU ~ visit + I(visit^2) + I(visit^3) + diagnosis + (1+visit + I(visit^2) + I(visit^3) |ID), data = data, REML=FALSE)

summary(Parental_model_cubic)


#Residual plot
plot(fitted(Parental_model_cubic),residuals(Parental_model_cubic))^2


#Plotting
ggplot(data = data, aes(x = visit, y = MOT_MLU, group = ID)) +
  geom_smooth(method = "lm", 
              formula = y ~ poly(x, 3), se = F, aes(color = ID)) + 
  geom_point(aes(col = ID)) + 
  facet_wrap(~ diagnosis) + 
  labs(x = xlab, y = ylab)

```


#Comparing the models
```{r ex3, include = FALSE}

#Checking for best model of MOT_MLU against null.
anova(model1.null, Parental_MLU, Parental_model_quadratic, Parental_model_cubic)

```


#Plotting the predictive quadratic
```{r}
# Plotting the best model's prediction (quadratic)

ee <- effect(c("diagnosis","visit"), Parental_model_quadratic) 
theme_set(theme_bw())

ggplot(as.data.frame(ee),
    aes(visit,fit,colour=diagnosis,fill=diagnosis)) +
    geom_line() +
    ## colour=NA suppresses edges of the ribbon
    geom_ribbon(colour=NA,alpha=0.1, aes(ymin=lower,ymax=upper)) +
    labs(title = "Predicting parental MLU development from diagnosis", x = "Visit", y = "MLU")
```


[REPORT THE RESULTS]

The quadratic model is the one with the lowest AIC. 
And most significant. 



### Adding new variables (Exercise 4)

Your task now is to figure out how to best describe the children linguistic trajectory.

The dataset contains a bunch of additional demographic, cognitive and clinical variables (e.g.verbal and non-verbal IQ). Try them out and identify the statistical models that best describes your data (that is, the children's MLU). 

Describe how you selected the best model and send the code to run the model to Malte (au540041@post.au.dk).


```{r}

#Correlation test too find variables that correlate / explain the same variance possibly

data_cor = select(data, visit, age, ados1, nonverbalIQ, verbalIQ, MOT_MLU, types_MOT, tokens_MOT, types_CHI, tokens_CHI, CHI_MLU)  %>%
  filter(!is.na(age)) %>% filter(!is.na(CHI_MLU))

corr = round(cor(data_cor,method = "spearman"),2)
corr

#Using corrplot to visually show the correlations
library(pacman)
p_load(corrplot, RColorBrewer)

corrplot(corr,method="color",col=brewer.pal(n=5, name="PuOr"),type="upper",tl.col="black", addgrid.col = "black")


```


Play with Ados
```{r ex4, include = FALSE}

#Trying to model the best model

#Using ados instead of diagnosis
model_ados <- lmer(CHI_MLU ~ visit + ados1 + (1 + visit| ID), data = data, REML=FALSE)
summary(model_ados)

#R-squared
r.squaredGLMM(model_ados)

####           R2m       R2c
####  [1,] 0.3420729 0.8020767

#More R2m than in model1. Ados might be better than diagnosis.

```


Play with MOT_MLU
```{r ex4, include = FALSE}
#Adding the parents MLU
model_MOT <- lmer(CHI_MLU ~ visit + MOT_MLU + (1 + visit| ID), data = data, REML=FALSE)

summary(model_MOT)
#A lot of variance seems to be explained by MOT_MLU


#R-squared
r.squaredGLMM(model_MOT)

###           R2m       R2c
### [<1,] 0.2886038 0.8098728

#Less that with ados but better than model1


#Comparing
anova(model_ados, model_MOT)
#MOT is better... 


#Combining the findings with ados and mot_mlu

#Cubic try with ados
model_ados_c <- lmer(CHI_MLU ~ visit + I(visit^2) + I(visit^3) + ados1 + (1+visit + I(visit^2) + I(visit^3)| ID), data = data, REML=FALSE)

summary(model_ados_c)
#alot is left to the residuals....

#R squared
r.squaredGLMM(model_ados_c)

##           R2m       R2c
##[1,] 0.2785971 0.8715399


#Quadratic with ados
model_ados_q <-lmer(CHI_MLU ~ visit + I(visit^2) + ados1 + (1+visit + I(visit^2) | ID), data = data, REML=FALSE)

r.squaredGLMM(model_ados_q)

#          R2m       R2c
# [1,] 0.2492597 0.8482384


#quadratic with both ados and mot_mlu
model_both_q <- lmer(CHI_MLU ~ visit + I(visit^2) + ados1 + MOT_MLU + (1+visit + I(visit^2) | ID), data = data, REML=FALSE)

summary(model_both_q)

r.squaredGLMM(model_both_q)
##           R2m       R2c
## [1,] 0.3041565 0.8507551


model_three_q <- lmer(CHI_MLU ~ visit + I(visit^2) + I(visit^3) + ados1 + MOT_MLU + verbalIQ + (1+visit + I(visit^2)+ I(visit^3)| ID), data = data, REML=FALSE)

summary(model_three_q)

r.squaredGLMM(model_three_q)
##           R2m       R2c
## [1,] 0.5190548 0.8495238

```


P-hacking
```{r ex4, include = FALSE}
###For fun best model 
p_hacked <- lmer(CHI_MLU ~ visit + I(visit^2) + I(visit^3) + ID + nonverbalIQ + verbalIQ + types_CHI + MOT_MLU + (1+visit + I(visit^2)+ I(visit^3)| ID), data = data, REML=FALSE)
summary(model_three_q)

r.squaredGLMM(p_hacked)

##          R2m       R2c
## [1,] 0.766436 0.8891787


###Comparing
anova(model_ados_c, model_ados_q, model_both_q, model_cubic)



model_both_q <- lmer(CHI_MLU ~ visit + I(visit^2) + ados1 + MOT_MLU + (1+visit + I(visit^2) | ID), data = data, REML=FALSE)

```


#Plotting with Ados
```{r}


##Plotting the data with ados
ggplot(data = data, aes(x = visit, y = CHI_MLU, group = ados1, colour = ados1)) +
  geom_smooth(method = "lm", 
              formula = y ~ poly(x, 3), se = F) + 
  geom_point() + 
  facet_wrap(~ diagnosis) + 
  labs(x = xlab, y = ylab) + 
  scale_color_gradient2(low = "blue", mid = "green", high = "red", midpoint = 10)



##Facet by ados
ggplot(data = data, aes(x = visit, y = CHI_MLU, group = ados1, colour = ados1)) +
  geom_smooth(method = "lm", 
              formula = y ~ poly(x, 3), se = F) + 
  geom_point() + 
  facet_wrap(~ ados1) + 
  labs(x = xlab, y = ylab) + 
  scale_color_gradient2(low = "blue", mid = "green", high = "red", midpoint = 10)




```


[REPORT THE RESULTS]

